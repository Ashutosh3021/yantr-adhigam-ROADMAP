{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6329f4ac",
   "metadata": {},
   "source": [
    "## Intro to Dataframes\n",
    "This section introduces basic pandas DataFrame operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7256837b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pandas library for data manipulation and analysis\n",
    "# Import numpy for numerical operations (often used with pandas)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a sample DataFrame with 4 rows and 3 columns\n",
    "# Data is organized in a 2D table format with custom column names (A, B, C) and row labels (x, y, z, zz)\n",
    "df = pd.DataFrame([[1,2,3],[4,5,6],[7,8,9],[10,11,12]], columns=[\"A\", \"B\", \"C\"], index=[\"x\",\"y\",\"z\",'zz'])\n",
    "\n",
    "# Display the first 5 rows of the DataFrame (default)\n",
    "# This helps you quickly see what your data looks like\n",
    "df.head()\n",
    "\n",
    "# Display the last 2 rows of the DataFrame\n",
    "# Useful for checking the end of your dataset\n",
    "df.tail(2)\n",
    "\n",
    "# Show all column names in the DataFrame\n",
    "# Returns an Index object containing the column labels\n",
    "df.columns\n",
    "\n",
    "# Get the row index labels and convert them to a regular Python list\n",
    "# This shows you all the row identifiers\n",
    "df.index.tolist()\n",
    "\n",
    "# Display detailed information about the DataFrame\n",
    "# Shows data types, memory usage, and number of non-null values for each column\n",
    "df.info()\n",
    "\n",
    "# Generate descriptive statistics for numerical columns\n",
    "# Shows count, mean, standard deviation, min, max, and quartiles\n",
    "df.describe()\n",
    "\n",
    "# Count the number of unique values in each column\n",
    "# Helps identify columns with categorical data or duplicates\n",
    "df.nunique()\n",
    "\n",
    "# Get unique values from column 'A' only\n",
    "# Returns an array of distinct values found in this column\n",
    "df['A'].unique()\n",
    "\n",
    "# Return the dimensions of the DataFrame as (rows, columns)\n",
    "# Shows how many rows and columns your data contains\n",
    "df.shape\n",
    "\n",
    "# Return the total number of elements in the DataFrame\n",
    "# This is rows × columns\n",
    "df.size\n",
    "\n",
    "# Display the entire DataFrame\n",
    "# Shows all data at once (use carefully with large datasets)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e92386",
   "metadata": {},
   "source": [
    "## Loading in Dataframes from Files\n",
    "This section shows how to load data from various file formats into pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fb20d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from CSV files into pandas DataFrames\n",
    "# coffee.csv contains coffee sales data\n",
    "# bios.csv contains athlete biographical information\n",
    "coffee = pd.read_csv('./warmup-data/coffee.csv')\n",
    "results = pd.read_parquet('./data/results.parquet')\n",
    "bios = pd.read_csv('./data/bios.csv')\n",
    "\n",
    "# To read an excel spreadsheet\n",
    "# Read data from an Excel file, specifying which sheet to load\n",
    "# This loads the 'results' sheet from the olympics-data.xlsx file\n",
    "olympics_data = pd.read_excel('./data/olympics-data.xlsx', sheet_name=\"results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94f7aa9",
   "metadata": {},
   "source": [
    "## Accessing Data with Pandas\n",
    "This section demonstrates different ways to view and access data in pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f82852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the coffee DataFrame to console (basic output)\n",
    "print(coffee)\n",
    "\n",
    "# Display the coffee DataFrame with better formatting (Jupyter-friendly)\n",
    "display(coffee)\n",
    "\n",
    "# Show first 5 rows of coffee data\n",
    "coffee.head()\n",
    "\n",
    "# Show last 10 rows of the coffee DataFrame\n",
    "# Good for checking recent data entries\n",
    "coffee.tail(10)\n",
    "\n",
    "# Get 5 random rows from the coffee DataFrame\n",
    "# Useful for getting a representative sample of your data\n",
    "# Note: Use random_state parameter for reproducible results\n",
    "coffee.sample(5) # Pass in random_state to make deterministic\n",
    "\n",
    "# Using .loc for label-based indexing\n",
    "# Syntax: coffee.loc[Rows, Columns]\n",
    "# Get the row with index label 0 (first row)\n",
    "coffee.loc[0]\n",
    "\n",
    "# Get multiple specific rows by their index labels\n",
    "# Returns rows with index 0, 1, and 5\n",
    "coffee.loc[[0,1,5]]\n",
    "\n",
    "# Get a slice of rows (from index 5 to 9) and specific columns\n",
    "# This selects rows 5 through 9 and only the 'Day' and 'Units Sold' columns\n",
    "coffee.loc[5:9, [\"Day\", \"Units Sold\"]]\n",
    "\n",
    "#### iloc - Integer position-based indexing\n",
    "# Get all rows (:) and columns at positions 0 and 2\n",
    "# This returns the first and third columns for every row\n",
    "coffee.iloc[:, [0,2]]\n",
    "\n",
    "#### Other Stuff\n",
    "# Set the DataFrame index to use the 'Day' column values\n",
    "# This makes it easier to select data by day names\n",
    "coffee.index = coffee[\"Day\"]\n",
    "\n",
    "# Now we can select rows by day names instead of numbers\n",
    "# Get all rows from Monday through Wednesday\n",
    "coffee.loc[\"Monday\":\"Wednesday\"]\n",
    "\n",
    "# Reload the coffee data to reset our changes (revert index back to default)\n",
    "coffee = pd.read_csv('./warmup-data/coffee.csv')\n",
    "\n",
    "#### Setting Values\n",
    "# Change the 'Units Sold' values for rows 1 through 3 to 10\n",
    "# This updates multiple cells at once with the same value\n",
    "coffee.loc[1:3, \"Units Sold\"] = 10\n",
    "\n",
    "#### Optimized way to get single values (.at & .iat)\n",
    "# .at gets a single value by label (faster than .loc for single values)\n",
    "# Gets the 'Units Sold' value from row with index 0\n",
    "coffee.at[0,\"Units Sold\"]\n",
    "\n",
    "# .iat gets a single value by integer position (faster than .iloc)\n",
    "# Gets the value at row 3, column 1 (0-indexed)\n",
    "coffee.iat[3,1]\n",
    "\n",
    "#### Getting Columns\n",
    "# Two ways to access a column:\n",
    "# Method 1: Using dot notation (works when column names don't have spaces)\n",
    "coffee.Day\n",
    "\n",
    "# Method 2: Using bracket notation (works for all column names)\n",
    "coffee[\"Day\"]\n",
    "\n",
    "#### Sort Values\n",
    "# Sort the DataFrame by 'Units Sold' column in descending order (highest first)\n",
    "coffee.sort_values([\"Units Sold\"], ascending=False)\n",
    "\n",
    "# Sort by multiple columns: first by 'Units Sold' (descending), then by 'Coffee Type' (ascending)\n",
    "# ascending=[0,1] means: 0=False (descending), 1=True (ascending)\n",
    "coffee.sort_values([\"Units Sold\", \"Coffee Type\"], ascending=[0,1])\n",
    "\n",
    "#### Iterate over dataframe with for loop\n",
    "# Loop through each row in the DataFrame\n",
    "# index = row index, row = Series containing all column values for that row\n",
    "for index, row in coffee.iterrows():\n",
    "    print(index)  # Print the row index\n",
    "    print(row)    # Print all column values for this row\n",
    "    print(\"Coffee Type of Row:\", row[\"Coffee Type\"])  # Print specific column value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a3d7d6",
   "metadata": {},
   "source": [
    "## Filtering Data\n",
    "This section covers how to filter DataFrames based on various conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb14b6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show first few rows of the bios DataFrame to understand its structure\n",
    "bios.head()\n",
    "\n",
    "# Filter rows where height_cm is greater than 215 cm\n",
    "# This returns only the athletes who are taller than 215 cm\n",
    "bios.loc[bios[\"height_cm\"] > 215]\n",
    "\n",
    "# Filter rows with height > 215 AND select only specific columns\n",
    "# Returns just the name and height columns for tall athletes\n",
    "bios.loc[bios[\"height_cm\"] > 215, [\"name\", \"height_cm\"]]\n",
    "\n",
    "#### Short-hand syntax (without .loc)\n",
    "# Alternative way to filter and select columns in one line\n",
    "# First filter by condition, then select columns using bracket notation\n",
    "bios[bios['height_cm'] > 215][[\"name\",\"height_cm\"]]\n",
    "\n",
    "#### Multiple filter conditions\n",
    "# Filter with multiple conditions using & (AND operator)\n",
    "# Find athletes who are both tall (height > 215) AND from USA\n",
    "bios[(bios['height_cm'] > 215) & (bios['born_country']=='USA')]\n",
    "\n",
    "#### Filter by string conditions\n",
    "# Find rows where the 'name' column contains the text \"keith\" (case-insensitive)\n",
    "# case=False means it matches both \"Keith\" and \"keith\"\n",
    "bios[bios['name'].str.contains(\"keith\", case=False)]\n",
    "\n",
    "# Regex syntax\n",
    "# Find names containing either \"keith\" OR \"patrick\" using regex pattern\n",
    "# The | symbol means \"or\" in regex\n",
    "bios[bios['name'].str.contains('keith|patrick', case=False)]\n",
    "\n",
    "# Other cool regex filters\n",
    "\n",
    "# Find athletes born in cities that start with a vowel (A, E, I, O, U):\n",
    "# ^ means start of string, [AEIOUaeiou] means any vowel character\n",
    "vowel_cities = bios[bios['born_city'].str.contains(r'^[AEIOUaeiou]', na=False)]\n",
    "\n",
    "# Find athletes with names that contain exactly two vowels:\n",
    "# This complex regex matches names with exactly 2 vowel characters\n",
    "# [^AEIOUaeiou] means any non-vowel character\n",
    "# The pattern ensures exactly 2 vowels with any non-vowels in between\n",
    "# Note: This is quite complex - just shows the power of regex!\n",
    "two_vowels = bios[bios['name'].str.contains(r'^[^AEIOUaeiou]*[AEIOUaeiou][^AEIOUaeiou]*[AEIOUaeiou][^AEIOUaeiou]*$', na=False)]\n",
    "\n",
    "# Find athletes with names that have repeated consecutive letters:\n",
    "# (.)\\1 means capture any character (.) then match the same character again (\\1)\n",
    "# This finds names like \"Aaron\" (aa) or \"Emmett\" (tt)\n",
    "repeated_letters = bios[bios['name'].str.contains(r'(.)\\1', na=False)]\n",
    "\n",
    "# Find athletes with names ending in 'son' or 'sen':\n",
    "# son$ means 'son' at the end of string ($)\n",
    "# sen$ means 'sen' at the end of string\n",
    "# | means OR, so matches either pattern\n",
    "son_sen_names = bios[bios['name'].str.contains(r'son$|sen$', case=False, na=False)]\n",
    "\n",
    "# Find athletes born in a year starting with '19':\n",
    "# ^19 means the string starts with '19' (for years like 1985, 1992)\n",
    "born_19xx = bios[bios['born_date'].str.contains(r'^19', na=False)]\n",
    "\n",
    "# Find athletes with names that do not contain any vowels:\n",
    "# ^[^AEIOUaeiou]*$ means start (^) and end ($) with zero or more (*) non-vowels\n",
    "no_vowels = bios[bios['name'].str.contains(r'^[^AEIOUaeiou]*$', na=False)]\n",
    "\n",
    "# Find athletes whose names contain a hyphen or an apostrophe:\n",
    "# [-'] matches either a hyphen (-) or apostrophe (')\n",
    "hyphen_apostrophe = bios[bios['name'].str.contains(r\"[-']\", na=False)]\n",
    "\n",
    "# Find athletes with names that start and end with the same letter:\n",
    "# ^(.).*\\1$ captures first character (.), matches anything in between (.*), then matches the same first character (\\1)\n",
    "start_end_same = bios[bios['name'].str.contains(r'^(.).*\\1$', na=False, case=False)]\n",
    "\n",
    "# Find athletes with a born_city that has exactly 7 characters:\n",
    "# ^.{7}$ means exactly 7 of any characters (.) between start (^) and end ($)\n",
    "city_seven_chars = bios[bios['born_city'].str.contains(r'^.{7}$', na=False)]\n",
    "\n",
    "# Find athletes with names containing three or more vowels:\n",
    "# ([AEIOUaeiou].*){3,} means match vowel + any characters, repeated 3 or more times\n",
    "three_or_more_vowels = bios[bios['name'].str.contains(r'([AEIOUaeiou].*){3,}', na=False)]\n",
    "\n",
    "# Don't use regex search (exact match)\n",
    "# This looks for the exact string 'keith|patrick' (not using regex pattern matching)\n",
    "bios[bios['name'].str.contains('keith|patrick', case=False, regex=False)]\n",
    "\n",
    "## isin method & startswith\n",
    "# Find athletes from specific countries (USA, FRA, GBR) whose names start with \"Keith\"\n",
    "# isin() checks if values are in a list, startswith() checks beginning of strings\n",
    "bios[bios['born_country'].isin([\"USA\", \"FRA\", \"GBR\"]) & (bios['name'].str.startswith(\"Keith\"))]\n",
    "\n",
    "print(\"Make sure to smash that like button & subscribe tehehehe\")\n",
    "\n",
    "#### Query functions\n",
    "# Alternative way to filter using query syntax (more readable for complex conditions)\n",
    "# Find athletes born in USA in the city of Seattle\n",
    "bios.query('born_country == \"USA\" and born_city == \"Seattle\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e0d6dc",
   "metadata": {},
   "source": [
    "## Adding / Removing Columns\n",
    "This section shows how to modify DataFrame structure by adding, removing, and renaming columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26631c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show first few rows of coffee data to see current structure\n",
    "coffee.head()\n",
    "\n",
    "# Add a new column called 'price' with value 4.99 for all rows\n",
    "coffee['price'] = 4.99\n",
    "\n",
    "# Add a new column with conditional values using numpy.where()\n",
    "# If Coffee Type is 'Espresso', price is 3.99, otherwise 5.99\n",
    "coffee['new_price'] = np.where(coffee['Coffee Type']=='Espresso', 3.99, 5.99) \n",
    "\n",
    "# Display the DataFrame to see the new columns\n",
    "coffee\n",
    "\n",
    "# Remove the 'price' column permanently (inplace=True modifies the original DataFrame)\n",
    "coffee.drop(columns=['price'], inplace=True)\n",
    "\n",
    "# Alternative way to remove columns (creates a new DataFrame instead of modifying original)\n",
    "# coffee = coffee.drop(columns=['price'])\n",
    "\n",
    "# Reorder columns to a specific sequence\n",
    "coffee = coffee[['Day', 'Coffee Type', 'Units Sold', 'new_price']]\n",
    "\n",
    "# Create a calculated column: revenue = units sold × price\n",
    "coffee['revenue'] = coffee['Units Sold'] * coffee['new_price']\n",
    "\n",
    "# Display the updated DataFrame\n",
    "coffee\n",
    "\n",
    "# Rename the 'new_price' column to just 'price'\n",
    "coffee.rename(columns={'new_price': 'price'}, inplace=True)\n",
    "\n",
    "# Create a copy of the bios DataFrame for modification\n",
    "bios_new = bios.copy()\n",
    "\n",
    "# Extract first name from full name by splitting on spaces and taking first element\n",
    "bios_new['first_name'] = bios_new['name'].str.split(' ').str[0]\n",
    "\n",
    "# Filter to show only athletes with first name \"Keith\"\n",
    "bios_new.query('first_name == \"Keith\"')\n",
    "\n",
    "# Convert the born_date column from string to datetime format\n",
    "bios_new['born_datetime'] = pd.to_datetime(bios_new['born_date'])\n",
    "\n",
    "# Extract just the year from the datetime column\n",
    "bios_new['born_year'] = bios_new['born_datetime'].dt.year\n",
    "\n",
    "# Show name and birth year columns\n",
    "bios_new[['name','born_year']]\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "bios_new.to_csv('./data/bios_new.csv', index=False)\n",
    "\n",
    "# Add a categorical column based on height using lambda function\n",
    "# Short: < 165cm, Average: 165-184cm, Tall: ≥ 185cm\n",
    "bios['height_category'] = bios['height_cm'].apply(lambda x: 'Short' if x < 165 else ('Average' if x < 185 else 'Tall'))\n",
    "\n",
    "# Define a custom function to categorize athletes based on height and weight\n",
    "def categorize_athlete(row):\n",
    "    if row['height_cm'] < 175 and row['weight_kg'] < 70:\n",
    "        return 'Lightweight'\n",
    "    elif row['height_cm'] < 185 or row['weight_kg'] <= 80:\n",
    "        return 'Middleweight'\n",
    "    else:\n",
    "        return 'Heavyweight'\n",
    "\n",
    "# Apply the custom function to each row (axis=1 means row-wise)\n",
    "bios['Category'] = bios.apply(categorize_athlete, axis=1)\n",
    "\n",
    "# Show first few rows to see the new Category column\n",
    "bios.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69356e8",
   "metadata": {},
   "source": [
    "## Merging & Concatenating Data\n",
    "This section covers combining DataFrames from different sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08aa9c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the NOC (National Olympic Committee) regions data\n",
    "nocs = pd.read_csv('./data/noc_regions.csv')\n",
    "\n",
    "# Merge bios and nocs DataFrames based on country codes\n",
    "# left_on='born_country' means use 'born_country' column from bios DataFrame\n",
    "# right_on='NOC' means use 'NOC' column from nocs DataFrame\n",
    "# how='left' means keep all rows from bios, add matching data from nocs\n",
    "bios_new = pd.merge(bios, nocs, left_on='born_country', right_on='NOC', how='left')\n",
    "\n",
    "# Rename the 'region' column to 'born_country_full' for clarity\n",
    "bios_new.rename(columns={'region': 'born_country_full'}, inplace=True)\n",
    "\n",
    "# Create separate DataFrames for USA and Great Britain athletes\n",
    "usa = bios[bios['born_country']=='USA'].copy()\n",
    "gbr = bios[bios['born_country']=='GBR'].copy()\n",
    "\n",
    "# Combine the USA and GBR DataFrames vertically (stack them on top of each other)\n",
    "new_df = pd.concat([usa,gbr])\n",
    "\n",
    "# Show the last few rows of the combined DataFrame\n",
    "new_df.tail()\n",
    "\n",
    "# Merge results and bios DataFrames on athlete_id column\n",
    "# This combines performance data with athlete biographical data\n",
    "combined_df = pd.merge(results, bios, on='athlete_id', how='left')\n",
    "\n",
    "# Show first few rows of the merged DataFrame\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f710344",
   "metadata": {},
   "source": [
    "## Handling Null Values\n",
    "This section shows how to deal with missing data in DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80034d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set specific cells in 'Units Sold' column to NaN (Not a Number - missing values)\n",
    "coffee.loc[[2,3], 'Units Sold'] = np.nan\n",
    "\n",
    "# Fill missing values with the mean (average) of the column\n",
    "# This replaces NaN values with the calculated average\n",
    "# Make sure to set this to your Units Sold column if you want these changes to stick\n",
    "coffee['Units Sold'].fillna(coffee['Units Sold'].mean()) \n",
    "\n",
    "# Alternative method: interpolate missing values\n",
    "# This fills gaps by estimating values based on surrounding data points\n",
    "# coffee['Units Sold'] = coffee['Units Sold'].interpolate()\n",
    "coffee['Units Sold'].interpolate()\n",
    "\n",
    "# Remove rows that have missing values in the 'Units Sold' column\n",
    "# Use inplace=True if you want to update the coffee df permanently\n",
    "coffee.dropna(subset=['Units Sold'])\n",
    "\n",
    "# Alternative way: filter to keep only rows where 'Units Sold' is NOT null\n",
    "coffee[coffee['Units Sold'].notna()]\n",
    "\n",
    "# Display current state of the DataFrame\n",
    "coffee"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74143d5a",
   "metadata": {},
   "source": [
    "## Aggregating Data\n",
    "This section covers grouping and summarizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618f554a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show first few rows of bios data to understand structure\n",
    "bios.head()\n",
    "\n",
    "# Count how many times each city appears in the born_city column\n",
    "# This shows the most common birth cities\n",
    "bios['born_city'].value_counts()\n",
    "\n",
    "# For USA athletes only, count how many are from each region\n",
    "# Show top 10 most common regions\n",
    "bios[bios['born_country']=='USA']['born_region'].value_counts().head(10)\n",
    "\n",
    "# Show bottom 25 least common regions for USA athletes\n",
    "bios[bios['born_country']=='USA']['born_region'].value_counts().tail(25)\n",
    "\n",
    "#### Groupby function in Pandas\n",
    "# Group coffee data by Coffee Type and sum the Units Sold for each type\n",
    "coffee.groupby(['Coffee Type'])['Units Sold'].sum()\n",
    "\n",
    "# Group by Coffee Type and calculate average Units Sold for each type\n",
    "coffee.groupby(['Coffee Type'])['Units Sold'].mean()\n",
    "\n",
    "# Group by multiple columns and apply different aggregation functions\n",
    "# Sum Units Sold and calculate average price for each Coffee Type and Day combination\n",
    "coffee.groupby(['Coffee Type', 'Day']).agg({'Units Sold': 'sum', 'price': 'mean'})\n",
    "\n",
    "#### Pivot Tables\n",
    "# Create a pivot table showing revenue by Day (rows) and Coffee Type (columns)\n",
    "pivot = coffee.pivot(columns='Coffee Type', index='Day', values='revenue')\n",
    "\n",
    "# Sum all values in each column (total revenue by coffee type)\n",
    "pivot.sum()\n",
    "\n",
    "# Sum all values in each row (total revenue by day)\n",
    "pivot.sum(axis=1)\n",
    "\n",
    "#### Using datetime with Groupby\n",
    "# Convert born_date column to datetime format for time-based operations\n",
    "bios['born_date'] = pd.to_datetime(bios['born_date'])\n",
    "\n",
    "# Extract month from birth dates\n",
    "bios['month_born'] = bios['born_date'].dt.month\n",
    "\n",
    "# Extract year from birth dates\n",
    "bios['year_born'] = bios['born_date'].dt.year\n",
    "\n",
    "# Group by birth year and month, count athletes born in each period\n",
    "# reset_index() converts the result back to a regular DataFrame\n",
    "# sort_values() arranges results by count in descending order\n",
    "bios.groupby([bios['year_born'],bios['month_born']])['name'].count().reset_index().sort_values('name', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dda2d92",
   "metadata": {},
   "source": [
    "## Advanced Functionality\n",
    "This section covers more advanced pandas operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb7022d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift() - move data up or down, rank() - assign rankings, cumsum() - cumulative sum, rolling() - moving window calculations\n",
    "\n",
    "# Create a subset containing only Latte sales\n",
    "latte = coffee[coffee['Coffee Type']==\"Latte\"].copy()\n",
    "\n",
    "# Calculate 3-day rolling sum of Units Sold\n",
    "# This creates a moving total that includes the current day plus previous 2 days\n",
    "latte['3day'] = latte['Units Sold'].rolling(3).sum()\n",
    "\n",
    "# Display the results\n",
    "latte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53971450",
   "metadata": {},
   "source": [
    "## Advanced Functionality (cont.)\n",
    "This section demonstrates additional libraries that work with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1806057",
   "metadata": {},
   "outputs": [],
   "source": [
    "These two libraries didn't actually make it into final video\n",
    "\n",
    "# Install and import pyjanitor for data cleaning utilities\n",
    "!pip install pyjanitor\n",
    "import janitor\n",
    "\n",
    "# Clean column names (remove spaces, special characters, make lowercase)\n",
    "coffee.clean_names()\n",
    "\n",
    "# Install and import skimpy for quick data summaries\n",
    "!pip install skimpy\n",
    "from skimpy import skim\n",
    "\n",
    "# Generate a comprehensive summary of the results DataFrame\n",
    "skim(results)\n",
    "\n",
    "# Show basic DataFrame information\n",
    "coffee.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b60481",
   "metadata": {},
   "source": [
    "## New Functionality\n",
    "This section shows newer pandas features and additional examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877d65d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV file with default numpy backend\n",
    "results_numpy = pd.read_csv('./data/results.csv')\n",
    "\n",
    "# Read CSV file with pyarrow backend (faster performance)\n",
    "results_arrow = pd.read_csv('./data/results.csv', engine='pyarrow', dtype_backend='pyarrow')\n",
    "\n",
    "# Show memory usage and data types with numpy backend\n",
    "results_numpy.info()\n",
    "\n",
    "# Show memory usage and data types with pyarrow backend\n",
    "results_arrow.info()\n",
    "\n",
    "# Filter bios data for athletes from New Hampshire OR San Francisco\n",
    "filtered_bios = bios[(bios['born_region'] == 'New Hampshire') | (bios['born_city'] == 'San Francisco')]\n",
    "\n",
    "# Show first few rows of the bios DataFrame\n",
    "bios.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d5707e",
   "metadata": {},
   "source": [
    "## Additional DataFrame Example\n",
    "Creating a sample DataFrame with sales data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10830463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creating a DataFrame with sample sales data\n",
    "data = {\n",
    "    'Date': ['2024-05-01', '2024-05-01', '2024-05-01', '2024-05-02', '2024-05-02', '2024-05-03', '2024-05-03', '2024-05-03'],\n",
    "    'Item': ['Apple', 'Banana', 'Orange', 'Apple', 'Banana', 'Orange', 'Apple', 'Orange'],\n",
    "    'Units Sold': [30, 21, 15, 40, 34, 20, 45, 25],\n",
    "    'Price Per Unit': [1.0, 0.5, 0.75, 1.0, 0.5, 0.75, 1.0, 0.75],\n",
    "    'Salesperson': ['John', 'John', 'John', 'Alice', 'Alice', 'John', 'Alice', 'John']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "df\n",
    "\n",
    "# Create a pivot table showing total units sold by date and item\n",
    "# This reorganizes the data to show a summary view\n",
    "pivot_table = pd.pivot_table(df, values='Units Sold', index='Date', columns='Item', aggfunc='sum')\n",
    "pivot_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f574bef",
   "metadata": {},
   "source": [
    "## Data Visualization Example\n",
    "Creating a histogram to visualize athlete height distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d664da72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming your DataFrame is named 'bios' and already loaded\n",
    "# First, filter out rows where the height_cm data is missing\n",
    "bios_filtered = bios.dropna(subset=['height_cm'])\n",
    "\n",
    "# Plotting the histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(bios_filtered['height_cm'], bins=20, color='blue', edgecolor='black')\n",
    "\n",
    "plt.title('Distribution of Athlete Heights in Olympics')\n",
    "plt.xlabel('Height in cm')\n",
    "plt.ylabel('Number of Athletes')\n",
    "plt.grid(True)\n",
    "\n",
    "# Using a logarithmic scale for the y-axis if the data spread is wide\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b237d8",
   "metadata": {},
   "source": [
    "## What Next???\n",
    "Check out some of my other tutorials:\n",
    "- [Cleaning Data w/ Pandas](https://www.youtube.com/live/oad9tVEsfI0?si=qnDOg9BSRFxcP5gZ)\n",
    "- [Solving 100 Python Pandas Problems](https://youtu.be/i7v2m-ebXB4?si=VSJHnZryqMv8GW54)\n",
    "- [Real-world Data Analysis Problems w/ Python Pandas](https://youtu.be/eMOA1pPVUc4)\n",
    "\n",
    "Platforms to Try\n",
    "- [Stratascratch](https://stratascratch.com/?via=keith)\n",
    "- [Analyst Builder](https://www.analystbuilder.com/?via=keith)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
